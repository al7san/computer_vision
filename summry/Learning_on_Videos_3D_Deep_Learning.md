# üé¨ Lecture 13: Learning on Videos, 3D Deep Learning, and Scene Graphs
## Overview

This lecture extends computer vision from **static images** to **videos and structured scenes**.
It focuses on understanding **relationships, motion, temporal dynamics, and activities** using
deep learning models.

---

## üéØ Learning Objectives

By the end of this lecture, you should be able to:

- Explain **visual relationship modeling** between objects and scenes  
- Understand how **Graph Neural Networks (GNNs)** encode structured visual information  
- Describe **motion detection** and **multi-object tracking** pipelines  
- Infer **human actions and activities** from video sequences using temporal deep learning models  

---

## üîó Visual Relationships

**Visual relationships** describe how objects interact within a scene.

### Examples
- person **riding** horse  
- dog **next to** table  
- car **under** bridge  

They are represented as **triplets**:

(subject, predicate, object)

This representation captures both objects and their interactions.

---

## ‚ùì Why Visual Relationships Matter

Visual relationships enable **scene understanding**, not just object detection.

They support:
- Image captioning  
- Visual Question Answering (VQA)  
- Robotics reasoning  
- Surveillance and activity recognition  

They also allow **commonsense reasoning**, such as:
- ‚Äúcup on table‚Äù implies physical support  

---

## üß† Modeling Visual Relationships

Typical pipeline:
1. **CNN-based object detection**
   - Extract object features
2. **Predicate classification**
   - Learn interactions between object pairs
3. **Graph-based reasoning**
   - Build **scene graphs**

### Key Idea
Combine:
- Appearance  
- Spatial layout  
- Context  

to model relationships accurately.

---

## üï∏Ô∏è Graph Neural Networks (GNNs) for Visual Reasoning

**Graph Neural Networks** process:
- **Nodes** ‚Üí objects  
- **Edges** ‚Üí relationships  

They are well suited for **scene graph representations**.

### Example Scene Graph
- Nodes: person, bike  
- Edge: riding  

---

## ‚ùì Why Use GNNs in Computer Vision?

GNNs:
- Encode structured relationships  
- Model contextual reasoning across objects  

They improve:
- Scene graph generation  
- Visual Question Answering  
- Relationship detection  
- Human‚Äìobject interaction understanding  

---

## üéûÔ∏è Motion Detection

**Motion detection** aims to identify pixels or regions that move across frames.

### Common Methods
- Frame differencing  
- Background subtraction  
- Optical flow (Horn‚ÄìSchunck, Lucas‚ÄìKanade)  
- CNN-based motion segmentation  

---

## üåä Optical Flow

**Optical flow** estimates pixel-level motion vectors between consecutive frames.

### Applications
- Video stabilization  
- Action recognition  
- Object tracking  
- Autonomous driving  

---

## üéØ Object Tracking

**Object tracking** maintains object identity across video frames.

### Types
- **Single-Object Tracking (SOT)**  
- **Multi-Object Tracking (MOT)**  

### Tracking Pipeline
1. **Detection**
   - CNN-based detectors (YOLO, Faster R-CNN)
2. **Tracking**
   - Kalman filters, SORT, DeepSORT
3. **Data Association**
   - Match detections to existing object tracks

---

## üßç Activity Recognition

**Activity recognition** identifies actions from image sequences or videos.

### Examples
- Running  
- Jumping  
- Cooking  
- Fighting  
- Playing sports  

---

## ‚ö†Ô∏è Challenges in Activity Recognition

- Temporal dependencies  
- Variations in viewpoint and scale  
- Occlusion  
- Multi-person interactions  
- Long and complex activities  

---

## üõ†Ô∏è Techniques for Activity Inference

### 1Ô∏è‚É£ CNN + LSTM Models
- CNN extracts frame-level features  
- LSTM / RNN models temporal sequences  

---

### 2Ô∏è‚É£ 3D CNNs
Examples:
- C3D  
- I3D  

- Perform convolution in **space and time**  
- Strong temporal modeling  

---

### 3Ô∏è‚É£ Transformers for Video
- Spatiotemporal attention  
- State-of-the-art approaches:
  - TimeSformer  
  - Video Swin Transformer  

---

### 4Ô∏è‚É£ Pose-Based Activity Recognition
- Track body keypoints (skeletons) over time  
- Effective for:
  - Sports analysis  
  - Gesture recognition  
  - Safety monitoring  

---

## üß± Example Architecture for Video Understanding

1. Input video frames  
2. CNN feature extraction (ResNet, EfficientNet)  
3. Sequence modeling (LSTM / GRU / Transformer)  
4. Activity classification layer  

---

## üöÄ Applications

- Video surveillance  
- Human action recognition  
- Autonomous driving  
- Robotics and human‚Äìrobot interaction  
- Sports analytics  

---

## üìö References

- Khan et al., *Guide to CNNs for Computer Vision* (2018)  
- Chollet, *Deep Learning with Python* (2018)  
- Awad & Hassaballah, *Deep Learning in Computer Vision* (2020)  
- Elgendy, *Deep Learning for Vision Systems* (2020)
